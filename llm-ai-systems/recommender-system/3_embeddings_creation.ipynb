{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üë®üèª‚Äçüè´ Build Index </span>\n",
    "\n",
    "In this notebook you will create a feature group for your candidate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Start the timer\n",
    "notebook_start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-15 22:02:16,491 INFO: Initializing external client\n",
      "2025-03-15 22:02:16,491 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-15 22:02:24,822 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1218722\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login(api_key_value = \"Dkez37cDPamSnJUf.HDsceFNWsdWX9blAXWtJxcez9tYRKw6eDYN2TQ5AbNjr9lrQKlMLB7nAZ2wgGBQd\")\n",
    "\n",
    "fs = project.get_feature_store()\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üéØ Compute Candidate Embeddings </span>\n",
    "\n",
    "You start by computing candidate embeddings for all items in the training data.\n",
    "\n",
    "First, you load your candidate model. Recall that you uploaded it to the Hopsworks Model Registry in the previous notebook. If you don't have the model locally you can download it from the Model Registry using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (2 dirs, 4 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "model = mr.get_model(\n",
    "    name=\"candidate_model\",\n",
    "    version=1,\n",
    ")\n",
    "model_path = model.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already have the model saved locally you can simply replace `model_path` with the path to your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_model = tf.saved_model.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you compute the embeddings of all candidate items that were used to train the retrieval model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = model.get_feature_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (7.36s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `2`.\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df, _, _, _ = feature_view.train_validation_test_split(\n",
    "    validation_size=0.1, \n",
    "    test_size=0.1,\n",
    "    description='Retrieval dataset splits',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>t_dat</th>\n",
       "      <th>price</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>customers_age</th>\n",
       "      <th>customers_club_member_status</th>\n",
       "      <th>customers_age_group</th>\n",
       "      <th>articles_garment_group_name</th>\n",
       "      <th>articles_index_group_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f7048acb8188d98bde3a5c495475a3c86faafe0eede1f2...</td>\n",
       "      <td>670265002</td>\n",
       "      <td>1540252800000</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>46-55</td>\n",
       "      <td>Under-, Nightwear</td>\n",
       "      <td>Ladieswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5d34f84e6cbe9ec4706872bb65376097af1e53f0c7dac5...</td>\n",
       "      <td>751471035</td>\n",
       "      <td>1593475200000</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>26-35</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>Ladieswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baf6dc7ea8575732794751bb80824fe84fd40e6af86193...</td>\n",
       "      <td>719308002</td>\n",
       "      <td>1558137600000</td>\n",
       "      <td>0.059305</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>48.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>46-55</td>\n",
       "      <td>Dresses Ladies</td>\n",
       "      <td>Divided</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id article_id  \\\n",
       "0  f7048acb8188d98bde3a5c495475a3c86faafe0eede1f2...  670265002   \n",
       "1  5d34f84e6cbe9ec4706872bb65376097af1e53f0c7dac5...  751471035   \n",
       "2  baf6dc7ea8575732794751bb80824fe84fd40e6af86193...  719308002   \n",
       "\n",
       "           t_dat     price     month_sin  month_cos  customers_age  \\\n",
       "0  1540252800000  0.013542 -8.660254e-01   0.500000           48.0   \n",
       "1  1593475200000  0.033881  1.224647e-16  -1.000000           30.0   \n",
       "2  1558137600000  0.059305  5.000000e-01  -0.866025           48.0   \n",
       "\n",
       "  customers_club_member_status customers_age_group  \\\n",
       "0                       ACTIVE               46-55   \n",
       "1                       ACTIVE               26-35   \n",
       "2                       ACTIVE               46-55   \n",
       "\n",
       "  articles_garment_group_name articles_index_group_name  \n",
       "0           Under-, Nightwear                Ladieswear  \n",
       "1                    Trousers                Ladieswear  \n",
       "2              Dresses Ladies                   Divided  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles_garment_group_name</th>\n",
       "      <th>articles_index_group_name</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Under-, Nightwear</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>670265002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trousers</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>751471035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dresses Ladies</td>\n",
       "      <td>Divided</td>\n",
       "      <td>719308002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  articles_garment_group_name articles_index_group_name article_id\n",
       "0           Under-, Nightwear                Ladieswear  670265002\n",
       "1                    Trousers                Ladieswear  751471035\n",
       "2              Dresses Ladies                   Divided  719308002"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of input features for the candidate model\n",
    "candidate_features = [*candidate_model.signatures['serving_default'].structured_input_signature[-1].keys()]\n",
    "\n",
    "# Select the candidate features from the training DataFrame\n",
    "item_df = train_df[candidate_features]\n",
    "\n",
    "# Drop duplicate rows based on the 'article_id' column to get unique candidate items\n",
    "item_df.drop_duplicates(subset=\"article_id\", inplace=True)\n",
    "\n",
    "item_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorFlow dataset from the item DataFrame\n",
    "item_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    {col: item_df[col] for col in item_df})\n",
    "\n",
    "# Compute embeddings for all candidate items using the candidate_model\n",
    "candidate_embeddings = item_ds.batch(2048).map(\n",
    "    lambda x: (x[\"article_id\"], candidate_model(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Strictly speaking, you haven't actually computed the candidate embeddings yet, as the dataset functions are lazily evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">‚öôÔ∏è Data Preparation </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all article IDs and embeddings from the candidate_embeddings dataset\n",
    "all_article_ids = tf.concat([batch[0] for batch in candidate_embeddings], axis=0)\n",
    "all_embeddings = tf.concat([batch[1] for batch in candidate_embeddings], axis=0)\n",
    "\n",
    "# Convert tensors to numpy arrays\n",
    "all_article_ids_np = all_article_ids.numpy().astype(int)\n",
    "all_embeddings_np = all_embeddings.numpy()\n",
    "\n",
    "# Convert numpy arrays to lists\n",
    "items_ids_list = all_article_ids_np.tolist()\n",
    "embeddings_list = all_embeddings_np.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>670265002</td>\n",
       "      <td>[0.6440691947937012, -0.45159974694252014, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>751471035</td>\n",
       "      <td>[0.45408013463020325, -0.40176618099212646, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>719308002</td>\n",
       "      <td>[0.33983850479125977, 0.05192527174949646, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>759231002</td>\n",
       "      <td>[0.9627549648284912, -0.706524133682251, 1.202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>746518001</td>\n",
       "      <td>[-0.14691144227981567, 0.3576121926307678, 0.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                         embeddings\n",
       "0   670265002  [0.6440691947937012, -0.45159974694252014, 0.1...\n",
       "1   751471035  [0.45408013463020325, -0.40176618099212646, 0....\n",
       "2   719308002  [0.33983850479125977, 0.05192527174949646, 0.3...\n",
       "3   759231002  [0.9627549648284912, -0.706524133682251, 1.202...\n",
       "4   746518001  [-0.14691144227981567, 0.3576121926307678, 0.5..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "data_emb = pd.DataFrame({\n",
    "    'article_id': items_ids_list, \n",
    "    'embeddings': embeddings_list,\n",
    "})\n",
    "\n",
    "data_emb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">ü™Ñ Feature Group Creation </span>\n",
    "\n",
    "Now you are ready to create a feature group for your candidate embeddings.\n",
    "\n",
    "To begin with, you need to create your Embedding Index where you will specify the name of the embeddings feature and the embeddings length.\n",
    "Then you attach this index to the FG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsfs import embedding\n",
    "\n",
    "# Create the Embedding Index\n",
    "embedding_index = embedding.EmbeddingIndex()\n",
    "\n",
    "embedding_index.add_embedding(\n",
    "    \"embeddings\",                           # Embeddings feature name\n",
    "    len(data_emb[\"embeddings\"].iloc[0]),    # Embeddings length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1218722/fs/1206352/fg/1420706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 11948/11948 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: candidate_embeddings_fg_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1218722/jobs/named/candidate_embeddings_fg_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('candidate_embeddings_fg_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get or create the 'candidate_embeddings_fg' feature group\n",
    "candidate_embeddings_fg = fs.get_or_create_feature_group(\n",
    "    name=\"candidate_embeddings_fg\",\n",
    "    embedding_index=embedding_index,  # Specify the Embedding Index\n",
    "    primary_key=['article_id'],\n",
    "    version=1,\n",
    "    description='Embeddings for each article',\n",
    "    online_enabled=True,\n",
    ")\n",
    "\n",
    "candidate_embeddings_fg.insert(data_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">ü™Ñ Feature View Creation </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1218722/fs/1206352/fv/candidate_embeddings/version/1\n"
     ]
    }
   ],
   "source": [
    "# Get or create the 'candidate_embeddings' feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"candidate_embeddings\",\n",
    "    version=1,\n",
    "    description='Embeddings of each article',\n",
    "    query=candidate_embeddings_fg.select([\"article_id\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚åõÔ∏è Notebook Execution time: 206.37 seconds\n"
     ]
    }
   ],
   "source": [
    "# End the timer\n",
    "notebook_end_time = time.time()\n",
    "\n",
    "# Calculate and print the execution time\n",
    "notebook_execution_time = notebook_end_time - notebook_start_time\n",
    "print(f\"‚åõÔ∏è Notebook Execution time: {notebook_execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27\">‚è©Ô∏è Next Steps </span>\n",
    "\n",
    "At this point you have a recommender system that is able to generate a set of candidate items for a customer. However, many of these could be poor, as the candidate model was trained with only a few subset of the features. In the next notebook, you'll create a ranking dataset to train a *ranking model* to do more fine-grained predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
